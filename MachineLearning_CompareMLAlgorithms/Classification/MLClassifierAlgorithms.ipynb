{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holiday Package Prediciton\n",
    "\n",
    "### 1) Problem statement.\n",
    "\"Trips & Travel.Com\" company wants to enable and establish a viable business model to expand the customer base.\n",
    "One of the ways to expand the customer base is to introduce a new offering of packages. Currently, there are 5 types of packages the company is offering * Basic, Standard, Deluxe, Super Deluxe, King. Looking at the data of the last year, we observed that 18% of the customers purchased the packages. However, the marketing cost was quite high because customers were contacted at random without looking at the available information.\n",
    "The company is now planning to launch a new product i.e. Wellness Tourism Package. Wellness Tourism is defined as Travel that allows the traveler to maintain, enhance or kick-start a healthy lifestyle, and support or increase one's sense of well-being.\n",
    "However, this time company wants to harness the available data of existing and potential customers to make the marketing expenditure more efficient.\n",
    "### 2) Data Collection.\n",
    "The Dataset is collected from https://www.kaggle.com/datasets/susant4learning/holiday-package-purchase-prediction\n",
    "The data consists of 20 column and 4888 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      200000          1  41.0     Self Enquiry         3              6.0   \n",
       "1      200001          0  49.0  Company Invited         1             14.0   \n",
       "2      200002          1  37.0     Self Enquiry         1              8.0   \n",
       "3      200003          0  33.0  Company Invited         1              9.0   \n",
       "4      200004          0   NaN     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       3                3.0   \n",
       "1        Salaried    Male                       3                4.0   \n",
       "2     Free Lancer    Male                       3                4.0   \n",
       "3        Salaried  Female                       2                3.0   \n",
       "4  Small Business    Male                       2                3.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0        Single            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "2          Basic                    3.0        Single            7.0   \n",
       "3          Basic                    3.0      Divorced            2.0   \n",
       "4          Basic                    4.0      Divorced            1.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "2         1                       3       0                       0.0   \n",
       "3         1                       5       1                       1.0   \n",
       "4         0                       5       1                       0.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  \n",
       "2   Executive        17090.0  \n",
       "3   Executive        17909.0  \n",
       "4   Executive        18468.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Travel_1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4888, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CustomerID', 'ProdTaken', 'Age', 'TypeofContact', 'CityTier',\n",
       "       'DurationOfPitch', 'Occupation', 'Gender', 'NumberOfPersonVisiting',\n",
       "       'NumberOfFollowups', 'ProductPitched', 'PreferredPropertyStar',\n",
       "       'MaritalStatus', 'NumberOfTrips', 'Passport', 'PitchSatisfactionScore',\n",
       "       'OwnCar', 'NumberOfChildrenVisiting', 'Designation', 'MonthlyIncome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4888 entries, 0 to 4887\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   CustomerID                4888 non-null   int64  \n",
      " 1   ProdTaken                 4888 non-null   int64  \n",
      " 2   Age                       4662 non-null   float64\n",
      " 3   TypeofContact             4863 non-null   object \n",
      " 4   CityTier                  4888 non-null   int64  \n",
      " 5   DurationOfPitch           4637 non-null   float64\n",
      " 6   Occupation                4888 non-null   object \n",
      " 7   Gender                    4888 non-null   object \n",
      " 8   NumberOfPersonVisiting    4888 non-null   int64  \n",
      " 9   NumberOfFollowups         4843 non-null   float64\n",
      " 10  ProductPitched            4888 non-null   object \n",
      " 11  PreferredPropertyStar     4862 non-null   float64\n",
      " 12  MaritalStatus             4888 non-null   object \n",
      " 13  NumberOfTrips             4748 non-null   float64\n",
      " 14  Passport                  4888 non-null   int64  \n",
      " 15  PitchSatisfactionScore    4888 non-null   int64  \n",
      " 16  OwnCar                    4888 non-null   int64  \n",
      " 17  NumberOfChildrenVisiting  4822 non-null   float64\n",
      " 18  Designation               4888 non-null   object \n",
      " 19  MonthlyIncome             4655 non-null   float64\n",
      "dtypes: float64(7), int64(7), object(6)\n",
      "memory usage: 763.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "### Handling Missing values\n",
    "1. Handling Missing values\n",
    "2. Handling Duplicates\n",
    "3. Check data type\n",
    "4. Understand the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID                    0\n",
       "ProdTaken                     0\n",
       "Age                         226\n",
       "TypeofContact                25\n",
       "CityTier                      0\n",
       "DurationOfPitch             251\n",
       "Occupation                    0\n",
       "Gender                        0\n",
       "NumberOfPersonVisiting        0\n",
       "NumberOfFollowups            45\n",
       "ProductPitched                0\n",
       "PreferredPropertyStar        26\n",
       "MaritalStatus                 0\n",
       "NumberOfTrips               140\n",
       "Passport                      0\n",
       "PitchSatisfactionScore        0\n",
       "OwnCar                        0\n",
       "NumberOfChildrenVisiting     66\n",
       "Designation                   0\n",
       "MonthlyIncome               233\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male       2916\n",
       "Female     1817\n",
       "Fe Male     155\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check all the categories \n",
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaritalStatus\n",
       "Married      2340\n",
       "Divorced      950\n",
       "Single        916\n",
       "Unmarried     682\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MaritalStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypeofContact\n",
       "Self Enquiry       3444\n",
       "Company Invited    1419\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TypeofContact'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductPitched\n",
       "Basic           1842\n",
       "Deluxe          1732\n",
       "Standard         742\n",
       "Super Deluxe     342\n",
       "King             230\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ProductPitched'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Designation\n",
       "Executive         1842\n",
       "Manager           1732\n",
       "Senior Manager     742\n",
       "AVP                342\n",
       "VP                 230\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Designation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male      2916\n",
       "Female    1972\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'] = df['Gender'].replace('Fe Male', 'Female')\n",
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaritalStatus\n",
       "Married      2340\n",
       "Unmarried    1598\n",
       "Divorced      950\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MaritalStatus'] = df['MaritalStatus'].replace('Single', 'Unmarried')\n",
    "df['MaritalStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      200000          1  41.0     Self Enquiry         3              6.0   \n",
       "1      200001          0  49.0  Company Invited         1             14.0   \n",
       "2      200002          1  37.0     Self Enquiry         1              8.0   \n",
       "3      200003          0  33.0  Company Invited         1              9.0   \n",
       "4      200004          0   NaN     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       3                3.0   \n",
       "1        Salaried    Male                       3                4.0   \n",
       "2     Free Lancer    Male                       3                4.0   \n",
       "3        Salaried  Female                       2                3.0   \n",
       "4  Small Business    Male                       2                3.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0     Unmarried            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "2          Basic                    3.0     Unmarried            7.0   \n",
       "3          Basic                    3.0      Divorced            2.0   \n",
       "4          Basic                    4.0      Divorced            1.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "2         1                       3       0                       0.0   \n",
       "3         1                       5       1                       1.0   \n",
       "4         0                       5       1                       0.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  \n",
       "2   Executive        17090.0  \n",
       "3   Executive        17909.0  \n",
       "4   Executive        18468.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age 4.62357 % missing values\n",
      "TypeofContact 0.51146 % missing values\n",
      "DurationOfPitch 5.13502 % missing values\n",
      "NumberOfFollowups 0.92062 % missing values\n",
      "PreferredPropertyStar 0.53191 % missing values\n",
      "NumberOfTrips 2.86416 % missing values\n",
      "NumberOfChildrenVisiting 1.35025 % missing values\n",
      "MonthlyIncome 4.76678 % missing values\n"
     ]
    }
   ],
   "source": [
    "## Check Missing Values\n",
    "## These are the features with nan value\n",
    "features_with_na=[features for features in df.columns if df[features].isnull().sum()>=1]\n",
    "for feature in features_with_na:\n",
    "    print(feature,np.round(df[feature].isnull().mean()*100,5), '% missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4662.000000</td>\n",
       "      <td>4637.000000</td>\n",
       "      <td>4843.000000</td>\n",
       "      <td>4862.000000</td>\n",
       "      <td>4748.000000</td>\n",
       "      <td>4822.000000</td>\n",
       "      <td>4655.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.622265</td>\n",
       "      <td>15.490835</td>\n",
       "      <td>3.708445</td>\n",
       "      <td>3.581037</td>\n",
       "      <td>3.236521</td>\n",
       "      <td>1.187267</td>\n",
       "      <td>23619.853491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.316387</td>\n",
       "      <td>8.519643</td>\n",
       "      <td>1.002509</td>\n",
       "      <td>0.798009</td>\n",
       "      <td>1.849019</td>\n",
       "      <td>0.857861</td>\n",
       "      <td>5380.698361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20346.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22347.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>98678.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age  DurationOfPitch  NumberOfFollowups  PreferredPropertyStar  \\\n",
       "count  4662.000000      4637.000000        4843.000000            4862.000000   \n",
       "mean     37.622265        15.490835           3.708445               3.581037   \n",
       "std       9.316387         8.519643           1.002509               0.798009   \n",
       "min      18.000000         5.000000           1.000000               3.000000   \n",
       "25%      31.000000         9.000000           3.000000               3.000000   \n",
       "50%      36.000000        13.000000           4.000000               3.000000   \n",
       "75%      44.000000        20.000000           4.000000               4.000000   \n",
       "max      61.000000       127.000000           6.000000               5.000000   \n",
       "\n",
       "       NumberOfTrips  NumberOfChildrenVisiting  MonthlyIncome  \n",
       "count    4748.000000               4822.000000    4655.000000  \n",
       "mean        3.236521                  1.187267   23619.853491  \n",
       "std         1.849019                  0.857861    5380.698361  \n",
       "min         1.000000                  0.000000    1000.000000  \n",
       "25%         2.000000                  1.000000   20346.000000  \n",
       "50%         3.000000                  1.000000   22347.000000  \n",
       "75%         4.000000                  2.000000   25571.000000  \n",
       "max        22.000000                  3.000000   98678.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics on numerical columns (Null cols)\n",
    "df[features_with_na].select_dtypes(exclude='object').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Null values\n",
    "1. Impute Median value for Age column\n",
    "2. Impute Mode for Type of Contract\n",
    "3. Impute Median for Duration of Pitch\n",
    "4. Impute Mode for NumberofFollowup as it is Discrete feature\n",
    "5. Impute Mode for PreferredPropertyStar\n",
    "6. Impute Median for NumberofTrips\n",
    "7. Impute Mode for NumberOfChildrenVisiting\n",
    "8. Impute Median for MonthlyIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age\n",
    "df.Age.fillna(df.Age.median(), inplace=True)\n",
    "\n",
    "#TypeofContract\n",
    "df.TypeofContact.fillna(df.TypeofContact.mode()[0], inplace=True)\n",
    "\n",
    "#DurationOfPitch\n",
    "df.DurationOfPitch.fillna(df.DurationOfPitch.median(), inplace=True)\n",
    "\n",
    "#NumberOfFollowups\n",
    "df.NumberOfFollowups.fillna(df.NumberOfFollowups.mode()[0], inplace=True)\n",
    "\n",
    "#PreferredPropertyStar\n",
    "df.PreferredPropertyStar.fillna(df.PreferredPropertyStar.mode()[0], inplace=True)\n",
    "\n",
    "#NumberOfTrips\n",
    "df.NumberOfTrips.fillna(df.NumberOfTrips.median(), inplace=True)\n",
    "\n",
    "#NumberOfChildrenVisiting\n",
    "df.NumberOfChildrenVisiting.fillna(df.NumberOfChildrenVisiting.mode()[0], inplace=True)\n",
    "\n",
    "#MonthlyIncome\n",
    "df.MonthlyIncome.fillna(df.MonthlyIncome.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID                  0\n",
       "ProdTaken                   0\n",
       "Age                         0\n",
       "TypeofContact               0\n",
       "CityTier                    0\n",
       "DurationOfPitch             0\n",
       "Occupation                  0\n",
       "Gender                      0\n",
       "NumberOfPersonVisiting      0\n",
       "NumberOfFollowups           0\n",
       "ProductPitched              0\n",
       "PreferredPropertyStar       0\n",
       "MaritalStatus               0\n",
       "NumberOfTrips               0\n",
       "Passport                    0\n",
       "PitchSatisfactionScore      0\n",
       "OwnCar                      0\n",
       "NumberOfChildrenVisiting    0\n",
       "Designation                 0\n",
       "MonthlyIncome               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('CustomerID', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0          1  41.0     Self Enquiry         3              6.0   \n",
       "1          0  49.0  Company Invited         1             14.0   \n",
       "2          1  37.0     Self Enquiry         1              8.0   \n",
       "3          0  33.0  Company Invited         1              9.0   \n",
       "4          0  36.0     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       3                3.0   \n",
       "1        Salaried    Male                       3                4.0   \n",
       "2     Free Lancer    Male                       3                4.0   \n",
       "3        Salaried  Female                       2                3.0   \n",
       "4  Small Business    Male                       2                3.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0     Unmarried            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "2          Basic                    3.0     Unmarried            7.0   \n",
       "3          Basic                    3.0      Divorced            2.0   \n",
       "4          Basic                    4.0      Divorced            1.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "2         1                       3       0                       0.0   \n",
       "3         1                       5       1                       1.0   \n",
       "4         0                       5       1                       0.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  \n",
       "2   Executive        17090.0  \n",
       "3   Executive        17909.0  \n",
       "4   Executive        18468.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>TotalVisiting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0          1  41.0     Self Enquiry         3              6.0   \n",
       "1          0  49.0  Company Invited         1             14.0   \n",
       "2          1  37.0     Self Enquiry         1              8.0   \n",
       "3          0  33.0  Company Invited         1              9.0   \n",
       "4          0  36.0     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfFollowups ProductPitched  \\\n",
       "0        Salaried  Female                3.0         Deluxe   \n",
       "1        Salaried    Male                4.0         Deluxe   \n",
       "2     Free Lancer    Male                4.0          Basic   \n",
       "3        Salaried  Female                3.0          Basic   \n",
       "4  Small Business    Male                3.0          Basic   \n",
       "\n",
       "   PreferredPropertyStar MaritalStatus  NumberOfTrips  Passport  \\\n",
       "0                    3.0     Unmarried            1.0         1   \n",
       "1                    4.0      Divorced            2.0         0   \n",
       "2                    3.0     Unmarried            7.0         1   \n",
       "3                    3.0      Divorced            2.0         1   \n",
       "4                    4.0      Divorced            1.0         0   \n",
       "\n",
       "   PitchSatisfactionScore  OwnCar Designation  MonthlyIncome  TotalVisiting  \n",
       "0                       2       1     Manager        20993.0            3.0  \n",
       "1                       3       1     Manager        20130.0            5.0  \n",
       "2                       3       0   Executive        17090.0            3.0  \n",
       "3                       5       1   Executive        17909.0            3.0  \n",
       "4                       5       1   Executive        18468.0            2.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new column for feature\n",
    "df['TotalVisiting'] = df['NumberOfPersonVisiting'] + df['NumberOfChildrenVisiting']\n",
    "df.drop(columns=['NumberOfPersonVisiting', 'NumberOfChildrenVisiting'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Numerical Features : 12\n",
      "Num of Categorical Features : 6\n",
      "Num of Discrete Features : 9\n",
      "Num of Continuous Features : 3\n"
     ]
    }
   ],
   "source": [
    "## Get all the numeric features\n",
    "num_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "print('Num of Numerical Features :', len(num_features))\n",
    "\n",
    "## Categorical features\n",
    "cat_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "print('Num of Categorical Features :', len(cat_features))\n",
    "\n",
    "## Discrete features\n",
    "discrete_features=[feature for feature in num_features if len(df[feature].unique())<=25]\n",
    "print('Num of Discrete Features :',len(discrete_features))\n",
    "\n",
    "## continuous features\n",
    "continuous_features=[feature for feature in num_features if feature not in discrete_features]\n",
    "print('Num of Continuous Features :',len(continuous_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split And Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['ProdTaken'], axis=1)\n",
    "y = df['ProdTaken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>TotalVisiting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age    TypeofContact  CityTier  DurationOfPitch      Occupation  Gender  \\\n",
       "0  41.0     Self Enquiry         3              6.0        Salaried  Female   \n",
       "1  49.0  Company Invited         1             14.0        Salaried    Male   \n",
       "2  37.0     Self Enquiry         1              8.0     Free Lancer    Male   \n",
       "3  33.0  Company Invited         1              9.0        Salaried  Female   \n",
       "4  36.0     Self Enquiry         1              8.0  Small Business    Male   \n",
       "\n",
       "   NumberOfFollowups ProductPitched  PreferredPropertyStar MaritalStatus  \\\n",
       "0                3.0         Deluxe                    3.0     Unmarried   \n",
       "1                4.0         Deluxe                    4.0      Divorced   \n",
       "2                4.0          Basic                    3.0     Unmarried   \n",
       "3                3.0          Basic                    3.0      Divorced   \n",
       "4                3.0          Basic                    4.0      Divorced   \n",
       "\n",
       "   NumberOfTrips  Passport  PitchSatisfactionScore  OwnCar Designation  \\\n",
       "0            1.0         1                       2       1     Manager   \n",
       "1            2.0         0                       3       1     Manager   \n",
       "2            7.0         1                       3       0   Executive   \n",
       "3            2.0         1                       5       1   Executive   \n",
       "4            1.0         0                       5       1   Executive   \n",
       "\n",
       "   MonthlyIncome  TotalVisiting  \n",
       "0        20993.0            3.0  \n",
       "1        20130.0            5.0  \n",
       "2        17090.0            3.0  \n",
       "3        17909.0            3.0  \n",
       "4        18468.0            2.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProdTaken\n",
       "0    3968\n",
       "1     920\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Categorical Features : 6\n",
      "Num of Numerical Features : 11\n"
     ]
    }
   ],
   "source": [
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "print('Num of Categorical Features :', len(cat_features))\n",
    "print('Num of Numerical Features :', len(num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Column Transformer with 3 types of transformers\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, cat_features),\n",
    "        (\"StandardScaler\", numeric_transformer, num_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;OneHotEncoder&#x27;, OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                 Index([&#x27;TypeofContact&#x27;, &#x27;Occupation&#x27;, &#x27;Gender&#x27;, &#x27;ProductPitched&#x27;,\n",
       "       &#x27;MaritalStatus&#x27;, &#x27;Designation&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;StandardScaler&#x27;, StandardScaler(),\n",
       "                                 Index([&#x27;Age&#x27;, &#x27;CityTier&#x27;, &#x27;DurationOfPitch&#x27;, &#x27;NumberOfFollowups&#x27;,\n",
       "       &#x27;PreferredPropertyStar&#x27;, &#x27;NumberOfTrips&#x27;, &#x27;Passport&#x27;,\n",
       "       &#x27;PitchSatisfactionScore&#x27;, &#x27;OwnCar&#x27;, &#x27;MonthlyIncome&#x27;, &#x27;TotalVisiting&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;ColumnTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(transformers=[(&#x27;OneHotEncoder&#x27;, OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                 Index([&#x27;TypeofContact&#x27;, &#x27;Occupation&#x27;, &#x27;Gender&#x27;, &#x27;ProductPitched&#x27;,\n",
       "       &#x27;MaritalStatus&#x27;, &#x27;Designation&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;StandardScaler&#x27;, StandardScaler(),\n",
       "                                 Index([&#x27;Age&#x27;, &#x27;CityTier&#x27;, &#x27;DurationOfPitch&#x27;, &#x27;NumberOfFollowups&#x27;,\n",
       "       &#x27;PreferredPropertyStar&#x27;, &#x27;NumberOfTrips&#x27;, &#x27;Passport&#x27;,\n",
       "       &#x27;PitchSatisfactionScore&#x27;, &#x27;OwnCar&#x27;, &#x27;MonthlyIncome&#x27;, &#x27;TotalVisiting&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">OneHotEncoder</label><div class=\"sk-toggleable__content \"><pre>Index([&#x27;TypeofContact&#x27;, &#x27;Occupation&#x27;, &#x27;Gender&#x27;, &#x27;ProductPitched&#x27;,\n",
       "       &#x27;MaritalStatus&#x27;, &#x27;Designation&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">StandardScaler</label><div class=\"sk-toggleable__content \"><pre>Index([&#x27;Age&#x27;, &#x27;CityTier&#x27;, &#x27;DurationOfPitch&#x27;, &#x27;NumberOfFollowups&#x27;,\n",
       "       &#x27;PreferredPropertyStar&#x27;, &#x27;NumberOfTrips&#x27;, &#x27;Passport&#x27;,\n",
       "       &#x27;PitchSatisfactionScore&#x27;, &#x27;OwnCar&#x27;, &#x27;MonthlyIncome&#x27;, &#x27;TotalVisiting&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content \"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('OneHotEncoder', OneHotEncoder(drop='first'),\n",
       "                                 Index(['TypeofContact', 'Occupation', 'Gender', 'ProductPitched',\n",
       "       'MaritalStatus', 'Designation'],\n",
       "      dtype='object')),\n",
       "                                ('StandardScaler', StandardScaler(),\n",
       "                                 Index(['Age', 'CityTier', 'DurationOfPitch', 'NumberOfFollowups',\n",
       "       'PreferredPropertyStar', 'NumberOfTrips', 'Passport',\n",
       "       'PitchSatisfactionScore', 'OwnCar', 'MonthlyIncome', 'TotalVisiting'],\n",
       "      dtype='object'))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3910, 17), (978, 17))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## applying Transformation in training(fit_transform)\n",
    "X_train=preprocessor.fit_transform(X_train)\n",
    "\n",
    "## applying transformation on test(transform)\n",
    "X_test=preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.721400</td>\n",
       "      <td>-1.020350</td>\n",
       "      <td>1.284279</td>\n",
       "      <td>-0.725271</td>\n",
       "      <td>-0.127737</td>\n",
       "      <td>-0.632399</td>\n",
       "      <td>0.679690</td>\n",
       "      <td>0.782966</td>\n",
       "      <td>-0.382245</td>\n",
       "      <td>-0.774151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.721400</td>\n",
       "      <td>0.690023</td>\n",
       "      <td>0.282777</td>\n",
       "      <td>-0.725271</td>\n",
       "      <td>1.511598</td>\n",
       "      <td>-0.632399</td>\n",
       "      <td>0.679690</td>\n",
       "      <td>0.782966</td>\n",
       "      <td>-0.459799</td>\n",
       "      <td>0.643615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.721400</td>\n",
       "      <td>-1.020350</td>\n",
       "      <td>0.282777</td>\n",
       "      <td>1.771041</td>\n",
       "      <td>0.418708</td>\n",
       "      <td>-0.632399</td>\n",
       "      <td>0.679690</td>\n",
       "      <td>0.782966</td>\n",
       "      <td>-0.245196</td>\n",
       "      <td>-0.065268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.721400</td>\n",
       "      <td>-1.020350</td>\n",
       "      <td>1.284279</td>\n",
       "      <td>-0.725271</td>\n",
       "      <td>-0.127737</td>\n",
       "      <td>-0.632399</td>\n",
       "      <td>1.408395</td>\n",
       "      <td>-1.277194</td>\n",
       "      <td>0.213475</td>\n",
       "      <td>-0.065268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.721400</td>\n",
       "      <td>2.400396</td>\n",
       "      <td>-1.720227</td>\n",
       "      <td>-0.725271</td>\n",
       "      <td>1.511598</td>\n",
       "      <td>-0.632399</td>\n",
       "      <td>-0.049015</td>\n",
       "      <td>-1.277194</td>\n",
       "      <td>-0.024889</td>\n",
       "      <td>2.061382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3905</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.721400</td>\n",
       "      <td>-0.653841</td>\n",
       "      <td>1.284279</td>\n",
       "      <td>-0.725271</td>\n",
       "      <td>-0.674182</td>\n",
       "      <td>-0.632399</td>\n",
       "      <td>-1.506426</td>\n",
       "      <td>0.782966</td>\n",
       "      <td>-0.536973</td>\n",
       "      <td>0.643615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.455047</td>\n",
       "      <td>-0.898180</td>\n",
       "      <td>-0.718725</td>\n",
       "      <td>1.771041</td>\n",
       "      <td>-1.220627</td>\n",
       "      <td>-0.632399</td>\n",
       "      <td>1.408395</td>\n",
       "      <td>0.782966</td>\n",
       "      <td>1.529609</td>\n",
       "      <td>-0.065268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.455047</td>\n",
       "      <td>1.545210</td>\n",
       "      <td>0.282777</td>\n",
       "      <td>-0.725271</td>\n",
       "      <td>2.058043</td>\n",
       "      <td>-0.632399</td>\n",
       "      <td>-0.777720</td>\n",
       "      <td>0.782966</td>\n",
       "      <td>-0.360576</td>\n",
       "      <td>0.643615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.455047</td>\n",
       "      <td>1.789549</td>\n",
       "      <td>1.284279</td>\n",
       "      <td>-0.725271</td>\n",
       "      <td>-0.127737</td>\n",
       "      <td>-0.632399</td>\n",
       "      <td>-1.506426</td>\n",
       "      <td>0.782966</td>\n",
       "      <td>-0.252799</td>\n",
       "      <td>0.643615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.721400</td>\n",
       "      <td>-0.776011</td>\n",
       "      <td>0.282777</td>\n",
       "      <td>-0.725271</td>\n",
       "      <td>-1.220627</td>\n",
       "      <td>1.581280</td>\n",
       "      <td>-0.049015</td>\n",
       "      <td>-1.277194</td>\n",
       "      <td>-1.082511</td>\n",
       "      <td>-1.483035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3910 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...        16  \\\n",
       "0     1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  ... -0.721400   \n",
       "1     1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  ... -0.721400   \n",
       "2     1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.721400   \n",
       "3     1.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  ... -0.721400   \n",
       "4     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.721400   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "3905  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  ... -0.721400   \n",
       "3906  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  1.455047   \n",
       "3907  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.455047   \n",
       "3908  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  1.455047   \n",
       "3909  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ... -0.721400   \n",
       "\n",
       "            17        18        19        20        21        22        23  \\\n",
       "0    -1.020350  1.284279 -0.725271 -0.127737 -0.632399  0.679690  0.782966   \n",
       "1     0.690023  0.282777 -0.725271  1.511598 -0.632399  0.679690  0.782966   \n",
       "2    -1.020350  0.282777  1.771041  0.418708 -0.632399  0.679690  0.782966   \n",
       "3    -1.020350  1.284279 -0.725271 -0.127737 -0.632399  1.408395 -1.277194   \n",
       "4     2.400396 -1.720227 -0.725271  1.511598 -0.632399 -0.049015 -1.277194   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3905 -0.653841  1.284279 -0.725271 -0.674182 -0.632399 -1.506426  0.782966   \n",
       "3906 -0.898180 -0.718725  1.771041 -1.220627 -0.632399  1.408395  0.782966   \n",
       "3907  1.545210  0.282777 -0.725271  2.058043 -0.632399 -0.777720  0.782966   \n",
       "3908  1.789549  1.284279 -0.725271 -0.127737 -0.632399 -1.506426  0.782966   \n",
       "3909 -0.776011  0.282777 -0.725271 -1.220627  1.581280 -0.049015 -1.277194   \n",
       "\n",
       "            24        25  \n",
       "0    -0.382245 -0.774151  \n",
       "1    -0.459799  0.643615  \n",
       "2    -0.245196 -0.065268  \n",
       "3     0.213475 -0.065268  \n",
       "4    -0.024889  2.061382  \n",
       "...        ...       ...  \n",
       "3905 -0.536973  0.643615  \n",
       "3906  1.529609 -0.065268  \n",
       "3907 -0.360576  0.643615  \n",
       "3908 -0.252799  0.643615  \n",
       "3909 -1.082511 -1.483035  \n",
       "\n",
       "[3910 rows x 26 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3995    0\n",
       "2610    0\n",
       "3083    0\n",
       "3973    0\n",
       "4044    0\n",
       "       ..\n",
       "4426    0\n",
       "466     0\n",
       "3092    0\n",
       "3772    0\n",
       "860     1\n",
       "Name: ProdTaken, Length: 3910, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ..., -1.2771941 ,\n",
       "        -0.73751038, -0.77415132],\n",
       "       [ 1.        ,  0.        ,  0.        , ..., -1.2771941 ,\n",
       "        -0.6704111 , -0.06526803],\n",
       "       [ 1.        ,  0.        ,  0.        , ...,  0.78296635,\n",
       "        -0.4208322 , -0.77415132],\n",
       "       ...,\n",
       "       [ 0.        ,  1.        ,  0.        , ...,  0.78296635,\n",
       "         0.69001249,  0.64361526],\n",
       "       [ 1.        ,  0.        ,  0.        , ...,  0.78296635,\n",
       "        -0.22827818, -0.77415132],\n",
       "       [ 1.        ,  1.        ,  0.        , ...,  0.78296635,\n",
       "        -0.44611323,  2.06138184]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.2-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-2.1.2-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Model Training And Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8460\n",
      "- F1 score: 0.8202\n",
      "- Precision: 0.7016\n",
      "- Recall: 0.3032\n",
      "- Roc Auc Score: 0.6368\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8364\n",
      "- F1 score: 0.8087\n",
      "- Precision: 0.6914\n",
      "- Recall: 0.2932\n",
      "- Roc Auc Score: 0.6307\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9141\n",
      "- F1 score: 0.9132\n",
      "- Precision: 0.7956\n",
      "- Recall: 0.7539\n",
      "- Roc Auc Score: 0.8535\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9305\n",
      "- F1 score: 0.9253\n",
      "- Precision: 0.9695\n",
      "- Recall: 0.6649\n",
      "- Roc Auc Score: 0.8299\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8939\n",
      "- F1 score: 0.8819\n",
      "- Precision: 0.8756\n",
      "- Recall: 0.5021\n",
      "- Roc Auc Score: 0.7429\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8589\n",
      "- F1 score: 0.8398\n",
      "- Precision: 0.7732\n",
      "- Recall: 0.3927\n",
      "- Roc Auc Score: 0.6824\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8565\n",
      "- F1 score: 0.8365\n",
      "- Precision: 0.7308\n",
      "- Recall: 0.3649\n",
      "- Roc Auc Score: 0.6670\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8354\n",
      "- F1 score: 0.8115\n",
      "- Precision: 0.6630\n",
      "- Recall: 0.3194\n",
      "- Roc Auc Score: 0.6400\n",
      "===================================\n",
      "\n",
      "\n",
      "Xgboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9995\n",
      "- F1 score: 0.9995\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9973\n",
      "- Roc Auc Score: 0.9986\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9427\n",
      "- F1 score: 0.9399\n",
      "- Precision: 0.9530\n",
      "- Recall: 0.7435\n",
      "- Roc Auc Score: 0.8673\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    \"Logistic Regression\":LogisticRegression(),\n",
    "    \"Decision Tree\":DecisionTreeClassifier(),\n",
    "    \"Random Forest\":RandomForestClassifier(),\n",
    "    \"Gradient Boost\":GradientBoostingClassifier(),\n",
    "    \"Adaboost\":AdaBoostClassifier(),\n",
    "    \"Xgboost\":XGBClassifier()\n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "    model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "    model_train_precision = precision_score(y_train, y_train_pred) # Calculate Precision\n",
    "    model_train_recall = recall_score(y_train, y_train_pred) # Calculate Recall\n",
    "    model_train_rocauc_score = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "    model_test_precision = precision_score(y_test, y_test_pred) # Calculate Precision\n",
    "    model_test_recall = recall_score(y_test, y_test_pred) # Calculate Recall\n",
    "    model_test_rocauc_score = roc_auc_score(y_test, y_test_pred) #Calculate Roc\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "    \n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "\n",
    "    \n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RF',\n",
       "  RandomForestClassifier(),\n",
       "  {'max_depth': [5, 8, 15, None, 10],\n",
       "   'max_features': ['auto', 'sqrt', 'log2'],\n",
       "   'min_samples_split': [2, 8, 15, 20],\n",
       "   'n_estimators': [100, 200, 500, 1000]}),\n",
       " ('AB',\n",
       "  AdaBoostClassifier(),\n",
       "  {'n_estimators': [50, 70, 90, 120, 180, 200],\n",
       "   'learning_rate': [0.001, 0.01, 0.1, 1, 10],\n",
       "   'algorithm': ['SAMME', 'SAMME.R']}),\n",
       " ('GradientBoost',\n",
       "  GradientBoostingClassifier(),\n",
       "  {'loss': ['log_loss', 'deviance', 'exponential'],\n",
       "   'criterion': ['friedman_mse', 'squared_error', 'mse'],\n",
       "   'min_samples_split': [2, 8, 15, 20],\n",
       "   'n_estimators': [100, 200, 500],\n",
       "   'max_depth': [5, 8, 15, None, 10],\n",
       "   'learning_rate': [0.01, 0.1, 0.2]}),\n",
       " ('Xgboost',\n",
       "  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "                gamma=None, grow_policy=None, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "                num_parallel_tree=None, random_state=None, ...),\n",
       "  {'learning_rate': [0.1, 0.01],\n",
       "   'max_depth': [5, 8, 12, 20, 30],\n",
       "   'n_estimators': [100, 200, 300],\n",
       "   'colsample_bytree': [0.5, 0.8, 1, 0.3, 0.4],\n",
       "   'min_child_weight': [4, 5, 6],\n",
       "   'reg_alpha': [0, 0.001, 0.005, 0.01, 0.05]})]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Hyperparameter Training\n",
    "rf_params = {\n",
    "    \"max_depth\": [5, 8, 15, None, 10],\n",
    "    \"max_features\": ['auto', 'sqrt', 'log2'],\n",
    "    \"min_samples_split\": [2, 8, 15, 20],\n",
    "    \"n_estimators\": [100, 200, 500, 1000]\n",
    "    }\n",
    "\n",
    "adaboost_params = {\n",
    "    'n_estimators' : [50, 70, 90, 120, 180, 200],\n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1, 10],\n",
    "    'algorithm':['SAMME','SAMME.R']\n",
    "    }\n",
    "\n",
    "gradient_params={\n",
    "    \"loss\": ['log_loss','deviance','exponential'],\n",
    "    \"criterion\": ['friedman_mse','squared_error','mse'],\n",
    "    \"min_samples_split\": [2, 8, 15, 20],\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"max_depth\": [5, 8, 15, None, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "    }\n",
    "\n",
    "xgboost_params = {\n",
    "    \"learning_rate\": [0.1, 0.01],\n",
    "    \"max_depth\": [5, 8, 12, 20, 30],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"colsample_bytree\": [0.5, 0.8, 1, 0.3, 0.4],\n",
    "    \"min_child_weight\":[4,5,6],\n",
    "    \"reg_alpha\":[0, 0.001, 0.005, 0.01, 0.05]\n",
    "    }\n",
    "\n",
    "randomcv_models = [\n",
    "    (\"RF\", RandomForestClassifier(), rf_params),\n",
    "    (\"AB\", AdaBoostClassifier(), adaboost_params),\n",
    "    (\"GradientBoost\", GradientBoostingClassifier(), gradient_params),\n",
    "    (\"Xgboost\", XGBClassifier(), xgboost_params)\n",
    "    ]\n",
    "\n",
    "randomcv_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=15, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=15, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=15, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=8, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=8, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=8, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=20, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=20, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=8, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=8, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=20, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=8, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=20, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=1000; total time=   1.5s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=1000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=1000; total time=   1.5s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=20, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=15, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=15, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=15, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=20, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=8, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=8, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=8, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=20, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=8, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=8, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=8, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=8, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=8, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=8, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=15, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=15, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=15, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=15, n_estimators=1000; total time=   2.5s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=15, n_estimators=1000; total time=   2.5s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=15, n_estimators=1000; total time=   2.5s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=15, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=2, n_estimators=1000; total time=   2.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=15, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=2, n_estimators=1000; total time=   2.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=15, n_estimators=1000; total time=   2.4s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=20, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=2, n_estimators=1000; total time=   2.9s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=20, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=20, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=20, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=20, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=20, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=20, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=2, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=2, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=2, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=2, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=8, max_features=log2, min_samples_split=2, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=15, n_estimators=1000; total time=   1.8s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=15, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=15, n_estimators=1000; total time=   1.8s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=20, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=20, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=20, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   1.5s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   1.5s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=15, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=15, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=2, n_estimators=1000; total time=   1.5s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   1.6s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=15, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=2, n_estimators=1000; total time=   1.4s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=2, n_estimators=1000; total time=   1.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=sqrt, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=20, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=20, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=20, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   1.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=20, n_estimators=1000; total time=   1.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=70; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=70; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=70; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=180; total time=   0.5s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=180; total time=   0.5s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=70; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=200; total time=   0.5s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=200; total time=   0.5s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=70; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.001, n_estimators=200; total time=   0.6s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=200; total time=   0.4s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=120; total time=   0.3s\n",
      "[CV] END ..algorithm=SAMME, learning_rate=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..algorithm=SAMME, learning_rate=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=120; total time=   0.3s\n",
      "[CV] END ..algorithm=SAMME, learning_rate=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=200; total time=   0.4s\n",
      "[CV] END ..algorithm=SAMME, learning_rate=1, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=120; total time=   0.3s\n",
      "[CV] END ..algorithm=SAMME, learning_rate=1, n_estimators=70; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=200; total time=   0.4s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.01, n_estimators=200; total time=   0.5s\n",
      "[CV] END ..algorithm=SAMME, learning_rate=1, n_estimators=90; total time=   0.2s\n",
      "[CV] END ..algorithm=SAMME, learning_rate=1, n_estimators=90; total time=   0.2s\n",
      "[CV] END ..algorithm=SAMME, learning_rate=1, n_estimators=70; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=180; total time=   0.4s\n",
      "[CV] END ..algorithm=SAMME, learning_rate=1, n_estimators=90; total time=   0.2s\n",
      "[CV] END .algorithm=SAMME, learning_rate=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END .algorithm=SAMME, learning_rate=1, n_estimators=120; total time=   0.3s\n",
      "[CV] END .algorithm=SAMME, learning_rate=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END .algorithm=SAMME, learning_rate=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END .algorithm=SAMME, learning_rate=1, n_estimators=120; total time=   0.3s\n",
      "[CV] END .algorithm=SAMME, learning_rate=10, n_estimators=70; total time=   0.1s\n",
      "[CV] END .algorithm=SAMME, learning_rate=1, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=200; total time=   0.4s\n",
      "[CV] END .algorithm=SAMME, learning_rate=10, n_estimators=70; total time=   0.1s\n",
      "[CV] END .algorithm=SAMME, learning_rate=1, n_estimators=180; total time=   0.5s\n",
      "[CV] END algorithm=SAMME, learning_rate=0.1, n_estimators=200; total time=   0.5s\n",
      "[CV] END .algorithm=SAMME, learning_rate=1, n_estimators=200; total time=   0.4s\n",
      "[CV] END .algorithm=SAMME, learning_rate=1, n_estimators=120; total time=   0.2s\n",
      "[CV] END .algorithm=SAMME, learning_rate=10, n_estimators=90; total time=   0.2s\n",
      "[CV] END .algorithm=SAMME, learning_rate=10, n_estimators=90; total time=   0.2s\n",
      "[CV] END .algorithm=SAMME, learning_rate=10, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME, learning_rate=10, n_estimators=120; total time=   0.3s\n",
      "[CV] END .algorithm=SAMME, learning_rate=10, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .algorithm=SAMME, learning_rate=1, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=10, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=10, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME, learning_rate=10, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME, learning_rate=10, n_estimators=120; total time=   0.3s\n",
      "[CV] END .algorithm=SAMME, learning_rate=1, n_estimators=200; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=70; total time=   0.2s\n",
      "[CV] END .algorithm=SAMME, learning_rate=1, n_estimators=200; total time=   0.5s\n",
      "[CV] END algorithm=SAMME, learning_rate=10, n_estimators=200; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=70; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=10, n_estimators=180; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME, learning_rate=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=180; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME, learning_rate=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=200; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=180; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=70; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=180; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=200; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=200; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=90; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=70; total time=   0.1s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=200; total time=   0.6s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=90; total time=   0.3s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=180; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=120; total time=   0.4s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=200; total time=   0.6s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=180; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=180; total time=   0.6s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=200; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=70; total time=   0.1s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=200; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=180; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=180; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=200; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=200; total time=   0.6s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=180; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=120; total time=   0.3s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=200; total time=   0.5s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=70; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=120; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=90; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=180; total time=   0.4s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=200; total time=   0.4s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=120; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=120; total time=   0.2s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=1, n_estimators=200; total time=   0.4s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=180; total time=   0.3s\n",
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=200; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansysoroush/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME.R, learning_rate=10, n_estimators=200; total time=   0.3s\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=10, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=10, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=10, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=8, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=8, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=8, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=deviance, max_depth=15, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=deviance, max_depth=15, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=deviance, max_depth=15, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=100; total time=   1.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=100; total time=   2.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=100; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=8, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=8, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=None, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=None, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=None, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=8, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=log_loss, max_depth=10, min_samples_split=15, n_estimators=500; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=8, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=100; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=log_loss, max_depth=10, min_samples_split=15, n_estimators=500; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=100; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=15, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=15, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=15, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=10, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=100; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=10, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=10, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=500; total time=   5.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=500; total time=   5.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=500; total time=   3.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=15, min_samples_split=15, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=100; total time=   2.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=100; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=log_loss, max_depth=10, min_samples_split=15, n_estimators=500; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, min_samples_split=20, n_estimators=500; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=10, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=deviance, max_depth=15, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=deviance, max_depth=15, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=deviance, max_depth=15, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, min_samples_split=20, n_estimators=500; total time=   2.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, min_samples_split=20, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=500; total time=   5.5s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=20, n_estimators=200; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=15, min_samples_split=15, n_estimators=100; total time=   1.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=20, n_estimators=200; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=500; total time=  12.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=15, min_samples_split=15, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=20, n_estimators=200; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=500; total time=   4.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=500; total time=   5.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=500; total time=   4.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=500; total time=   9.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=8, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=8, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=8, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=500; total time=  12.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=log_loss, max_depth=10, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=log_loss, max_depth=10, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=log_loss, max_depth=10, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=500; total time=  10.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=100; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=500; total time=   4.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=100; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=500; total time=   3.2s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=500; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=15, min_samples_split=15, n_estimators=500; total time=   9.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=100; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=500; total time=  11.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=15, min_samples_split=15, n_estimators=500; total time=   9.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=15, min_samples_split=15, n_estimators=500; total time=   9.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=15, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=15, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=15, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=500; total time=   9.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=10, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=10, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=None, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=None, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=None, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=15, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=15, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=15, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=10, min_samples_split=8, n_estimators=500; total time=   7.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=10, min_samples_split=8, n_estimators=500; total time=   7.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=10, min_samples_split=8, n_estimators=500; total time=   8.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=None, min_samples_split=15, n_estimators=100; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, min_samples_split=8, n_estimators=200; total time=   2.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, min_samples_split=8, n_estimators=200; total time=   2.9s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=15, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=15, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=15, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=deviance, max_depth=15, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=deviance, max_depth=15, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=deviance, max_depth=15, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=None, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=None, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=None, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=500; total time=   6.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=500; total time=   6.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=10, min_samples_split=8, n_estimators=200; total time=   3.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, max_depth=None, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, max_depth=None, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=deviance, max_depth=None, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=None, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=None, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=None, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=None, min_samples_split=15, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=500; total time=   9.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=None, min_samples_split=15, n_estimators=100; total time=   2.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=exponential, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=exponential, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=exponential, max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=log_loss, max_depth=15, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=log_loss, max_depth=15, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=log_loss, max_depth=15, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=None, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=None, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=None, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.2, loss=log_loss, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=500; total time=   6.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=500; total time=   9.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=500; total time=   9.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=8, n_estimators=200; total time=   3.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=8, n_estimators=200; total time=   3.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=5, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=None, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=None, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=None, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=8, n_estimators=200; total time=   3.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=log_loss, max_depth=None, min_samples_split=15, n_estimators=500; total time=   3.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=log_loss, max_depth=None, min_samples_split=15, n_estimators=500; total time=   3.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=500; total time=   5.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=500; total time=   6.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=10, min_samples_split=2, n_estimators=500; total time=   6.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.2, loss=log_loss, max_depth=None, min_samples_split=15, n_estimators=500; total time=   3.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=None, min_samples_split=20, n_estimators=500; total time=   8.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=None, min_samples_split=20, n_estimators=500; total time=   8.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=None, min_samples_split=20, n_estimators=500; total time=   7.9s\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=300, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=300, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=300, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, min_child_weight=6, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=300, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=200, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=300, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=200, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=300, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=200, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, min_child_weight=6, n_estimators=100, reg_alpha=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, min_child_weight=6, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, min_child_weight=6, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, min_child_weight=6, n_estimators=100, reg_alpha=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, min_child_weight=6, n_estimators=100, reg_alpha=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=100, reg_alpha=0.001; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0.005; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0.005; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0.005; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, min_child_weight=6, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=100, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=300, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=300, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=100, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, min_child_weight=6, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, min_child_weight=6, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=100, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, min_child_weight=6, n_estimators=200, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=300, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, min_child_weight=6, n_estimators=200, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0.001; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, min_child_weight=6, n_estimators=200, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0.001; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, min_child_weight=4, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, min_child_weight=5, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, min_child_weight=4, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, min_child_weight=5, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0.001; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, min_child_weight=5, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, min_child_weight=4, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=100, reg_alpha=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, min_child_weight=6, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, min_child_weight=5, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, min_child_weight=6, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=6, n_estimators=300, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=100, reg_alpha=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, min_child_weight=5, n_estimators=300, reg_alpha=0.05; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, min_child_weight=6, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, min_child_weight=4, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, min_child_weight=4, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, min_child_weight=5, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, min_child_weight=6, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, min_child_weight=4, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, min_child_weight=5, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, min_child_weight=5, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=6, n_estimators=300, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, min_child_weight=6, n_estimators=100, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, min_child_weight=6, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=6, n_estimators=300, reg_alpha=0.005; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, min_child_weight=6, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=300, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, min_child_weight=6, n_estimators=100, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, min_child_weight=6, n_estimators=100, reg_alpha=0.05; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, min_child_weight=5, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=300, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, min_child_weight=4, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, min_child_weight=4, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=300, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, min_child_weight=4, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=30, min_child_weight=6, n_estimators=300, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, min_child_weight=4, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=30, min_child_weight=6, n_estimators=300, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, min_child_weight=4, n_estimators=100, reg_alpha=0.001; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, min_child_weight=4, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, min_child_weight=4, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, min_child_weight=4, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, min_child_weight=4, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=30, min_child_weight=6, n_estimators=300, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0.001; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=300, reg_alpha=0.05; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0.05; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=300, reg_alpha=0.05; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=300, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=300, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, min_child_weight=5, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, min_child_weight=5, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0.05; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=300, reg_alpha=0.05; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=300, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, min_child_weight=5, n_estimators=200, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=6, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=300, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, min_child_weight=4, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, min_child_weight=4, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, min_child_weight=4, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=300, reg_alpha=0.01; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=6, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=200, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=200, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=6, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=300, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=6, n_estimators=200, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, min_child_weight=5, n_estimators=100, reg_alpha=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=300, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=300, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, min_child_weight=5, n_estimators=100, reg_alpha=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=300, reg_alpha=0.005; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, min_child_weight=5, n_estimators=100, reg_alpha=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=300, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=100, reg_alpha=0.001; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, min_child_weight=5, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=300, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, min_child_weight=5, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, min_child_weight=6, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=100, reg_alpha=0.05; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=300, reg_alpha=0.005; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=100, reg_alpha=0.05; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, min_child_weight=5, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, min_child_weight=6, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=100, reg_alpha=0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, min_child_weight=6, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=100, reg_alpha=0.05; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, min_child_weight=5, n_estimators=300, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=5, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=30, min_child_weight=5, n_estimators=300, reg_alpha=0.05; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=30, min_child_weight=5, n_estimators=300, reg_alpha=0.05; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, min_child_weight=5, n_estimators=300, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, min_child_weight=4, n_estimators=300, reg_alpha=0.001; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, min_child_weight=5, n_estimators=300, reg_alpha=0.01; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, min_child_weight=5, n_estimators=300, reg_alpha=0.01; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=100, reg_alpha=0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.01; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, min_child_weight=5, n_estimators=300, reg_alpha=0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=5, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, min_child_weight=5, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.05; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=100, reg_alpha=0.005; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, min_child_weight=5, n_estimators=300, reg_alpha=0.01; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.05; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=30, min_child_weight=5, n_estimators=300, reg_alpha=0.05; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, min_child_weight=5, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=100, reg_alpha=0.005; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, min_child_weight=5, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.05; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.01; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, min_child_weight=5, n_estimators=100, reg_alpha=0.001; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, min_child_weight=4, n_estimators=300, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, min_child_weight=6, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, min_child_weight=4, n_estimators=200, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.05; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, min_child_weight=4, n_estimators=300, reg_alpha=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, min_child_weight=4, n_estimators=300, reg_alpha=0.01; total time=   0.1s\n",
      "---------------- Best Params for RF -------------------\n",
      "{'n_estimators': 500, 'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': None}\n",
      "---------------- Best Params for AB -------------------\n",
      "{'n_estimators': 90, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "---------------- Best Params for GradientBoost -------------------\n",
      "{'n_estimators': 100, 'min_samples_split': 8, 'max_depth': 15, 'loss': 'exponential', 'learning_rate': 0.2, 'criterion': 'squared_error'}\n",
      "---------------- Best Params for Xgboost -------------------\n",
      "{'reg_alpha': 0.01, 'n_estimators': 200, 'min_child_weight': 4, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_param = {}\n",
    "for name, model, params in randomcv_models:\n",
    "    random = RandomizedSearchCV(estimator=model,\n",
    "                                param_distributions=params,\n",
    "                                n_iter=100,\n",
    "                                cv=3,\n",
    "                                verbose=2,\n",
    "                                random_state=42,\n",
    "                                n_jobs=-1)\n",
    "    random.fit(X_train, y_train)\n",
    "    model_param[name] = random.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"---------------- Best Params for {model_name} -------------------\")\n",
    "    print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9284\n",
      "- F1 score: 0.9228\n",
      "- Precision: 0.9690\n",
      "- Recall: 0.6545\n",
      "- Roc Auc Score: 0.8247\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8473\n",
      "- F1 score: 0.8142\n",
      "- Precision: 0.7750\n",
      "- Recall: 0.2551\n",
      "- Roc Auc Score: 0.6191\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8364\n",
      "- F1 score: 0.7977\n",
      "- Precision: 0.7818\n",
      "- Recall: 0.2251\n",
      "- Roc Auc Score: 0.6049\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9601\n",
      "- F1 score: 0.9587\n",
      "- Precision: 0.9750\n",
      "- Recall: 0.8168\n",
      "- Roc Auc Score: 0.9058\n",
      "===================================\n",
      "\n",
      "\n",
      "Xgboost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9376\n",
      "- F1 score: 0.9343\n",
      "- Precision: 0.9452\n",
      "- Recall: 0.7225\n",
      "- Roc Auc Score: 0.8562\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(n_estimators=500, min_samples_split=2,\n",
    "                                        max_features='sqrt', max_depth=None),\n",
    "    \"Adaboost Classifier\": AdaBoostClassifier(n_estimators=90, learning_rate=1, algorithm='SAMME'),\n",
    "    \"Gradient Boost Classifier\": GradientBoostingClassifier(n_estimators=100,\n",
    "                                                        min_samples_split=8,\n",
    "                                                        max_depth=15,\n",
    "                                                        loss='exponential',\n",
    "                                                        learning_rate=0.2,\n",
    "                                                        criterion='squared_error'),\n",
    "    \"Xgboost Classifier\": XGBClassifier(n_estimators=200,max_depth=12,learning_rate=0.1,\n",
    "                            colsample_bytree=1, min_child_weight=4, reg_alpha=0.01)\n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "    model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "    model_train_precision = precision_score(y_train, y_train_pred) # Calculate Precision\n",
    "    model_train_recall = recall_score(y_train, y_train_pred) # Calculate Recall\n",
    "    model_train_rocauc_score = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "    model_test_precision = precision_score(y_test, y_test_pred) # Calculate Precision\n",
    "    model_test_recall = recall_score(y_test, y_test_pred) # Calculate Recall\n",
    "    model_test_rocauc_score = roc_auc_score(y_test, y_test_pred) #Calculate Roc\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "    \n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "\n",
    "    \n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot ROC AUC Curve\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "plt.figure()\n",
    "\n",
    "# Add the models to the list that you want to view on the ROC plot\n",
    "auc_models = [\n",
    "{\n",
    "    'label': 'Random Forest',\n",
    "    'model': RandomForestClassifier(n_estimators=500, min_samples_split=2, max_features='sqrt', max_depth=None),\n",
    "    'auc':  0.8247\n",
    "},\n",
    "{\n",
    "    'label': 'Adaboost',\n",
    "    'model': AdaBoostClassifier(n_estimators=90, learning_rate=1, algorithm='SAMME'),\n",
    "    'auc':  0.6049\n",
    "},\n",
    "{\n",
    "    'label': 'Gradient Boost',\n",
    "    'model': GradientBoostingClassifier(n_estimators=100,\n",
    "                                        min_samples_split=8,\n",
    "                                        max_depth=15,\n",
    "                                        loss='exponential',\n",
    "                                        learning_rate=0.2,\n",
    "                                        criterion='squared_error'),\n",
    "    'auc':  0.9058\n",
    "},\n",
    "{\n",
    "    'label': 'Xgboost',\n",
    "    'model': XGBClassifier(n_estimators=200,max_depth=12,learning_rate=0.1,\n",
    "                            colsample_bytree=1, min_child_weight=4, reg_alpha=0.01),\n",
    "    'auc':  0.8562\n",
    "},]\n",
    "\n",
    "# create loop through all model\n",
    "for algo in auc_models:\n",
    "    model = algo['model'] # select the model\n",
    "    model.fit(X_train, y_train) # train the model\n",
    "# Compute False positive rate, and True positive rate\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "# Calculate Area under the curve to display on the plot\n",
    "    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (algo['label'], algo['auc']))\n",
    "# Custom settings for the plot \n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1-Specificity(False Positive Rate)')\n",
    "plt.ylabel('Sensitivity(True Positive Rate)')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"auc.png\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
